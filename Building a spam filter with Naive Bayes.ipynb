{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING A SPAM FILTER WITH NAIVE BAYES\n",
    "\n",
    "In this project, I'm going to build a spam filter for SMS messages by using the Multinomial Naive Bayes Algorithm.\n",
    "My goal is to build a spam filter that classifies the new SMS messages with an accuracy greater than 80%.\n",
    "To train the algorithm, I'll use this [dataset](https://data.world/lylepratt/sms-spam), created by Lyle Pratt, from [data.world](https://data.world/). The dataset is in .txt format. So I have converted it into a .csv file. The dataset contains 5,574 SMS that are already classified by humans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                               Text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5574 entries, 0 to 5573\n",
      "Data columns (total 2 columns):\n",
      "Label    5574 non-null object\n",
      "Text     5574 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary packages\n",
    "import pandas as pd\n",
    "\n",
    "#Reading in the dataset\n",
    "data = pd.read_csv(\"sms.csv\", encoding = \"unicode_escape\")\n",
    "print(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865985\n",
       "spam    0.134015\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 87% of the messages are ham and 13% are ham. Since, in reality, most messages that people receive are ham, the sample is considered to be representative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING AND TEST SET\n",
    "Now I'm going to split the dataset into training set and test set where training set will contain 80 % of the data, and the test set, 20 % of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training Set =  4459\n",
      "Number of rows in test Set =  1115\n"
     ]
    }
   ],
   "source": [
    "#Randomizing the dataset\n",
    "random_data = data.sample(frac=1, random_state=1)\n",
    "\n",
    "#Index for splitting\n",
    "index = round(len(random_data)*0.8)\n",
    "\n",
    "#Splitting the dataset\n",
    "training_set = random_data[:index].reset_index(drop=True)\n",
    "test_set = random_data[index:].reset_index(drop=True)\n",
    "\n",
    "print(\"Number of rows in training Set = \",training_set.shape[0])\n",
    "print(\"Number of rows in test Set = \",test_set.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now calculate the percentage of spam and ham emails in training and test sets. The percentages should be closer to what was calculated for the full dataset. Let's analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865216\n",
       "spam    0.134784\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.869058\n",
       "spam    0.130942\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spam and ham percentages are close to the percentages in the full dataset. So let's move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING\n",
    "\n",
    "#### 1. CONVERTING TO LOWERCASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>looks like u wil b getting a headstart im leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>i noe la... u wana pei bf oso rite... k lor, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>2mro i am not coming to gym machan. goodnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>spam</td>\n",
       "      <td>todays vodafone numbers ending with 4882 are s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>hi. hope ur day * good! back from walk, table ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  looks like u wil b getting a headstart im leav...\n",
       "1   ham  i noe la... u wana pei bf oso rite... k lor, o...\n",
       "2   ham     2mro i am not coming to gym machan. goodnight.\n",
       "3  spam  todays vodafone numbers ending with 4882 are s...\n",
       "4   ham  hi. hope ur day * good! back from walk, table ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[\"Text\"] = training_set[\"Text\"].str.lower()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. REMOVING PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>looks like u wil b getting a headstart im leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>i noe la    u wana pei bf oso rite    k lor  o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>2mro i am not coming to gym machan  goodnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>spam</td>\n",
       "      <td>todays vodafone numbers ending with 4882 are s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>hi  hope ur day   good  back from walk  table ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  looks like u wil b getting a headstart im leav...\n",
       "1   ham  i noe la    u wana pei bf oso rite    k lor  o...\n",
       "2   ham     2mro i am not coming to gym machan  goodnight \n",
       "3  spam  todays vodafone numbers ending with 4882 are s...\n",
       "4   ham  hi  hope ur day   good  back from walk  table ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def punctuation(text):\n",
    "    return re.sub('\\W',' ',text)\n",
    "training_set[\"Text\"] = training_set[\"Text\"].apply(punctuation)\n",
    "training_set.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOCABULARY\n",
    "\n",
    "I'll now create a vocabulary, which is a list of all the unique words in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total words =  72469\n",
      "Number of unique words =  7798\n"
     ]
    }
   ],
   "source": [
    "#Splitting each line into words\n",
    "training_set[\"Text\"] = training_set[\"Text\"].str.split()\n",
    "\n",
    "#Creating an empty list\n",
    "vocab = []\n",
    "for text in training_set[\"Text\"]:\n",
    "    for word in text:\n",
    "        vocab.append(word)\n",
    "print(\"Number of total words = \",len(vocab))        \n",
    "\n",
    "#converting list to set removes all the duplicate values.\n",
    "#So I'm converting the list to set and then converting the set to list, to get only the unique values\n",
    "vocab = list(set(vocab))\n",
    "print(\"Number of unique words = \",len(vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to create a dataframe that shows whether the message contains the words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {uniqueword : [0]*len(training_set[\"Text\"]) for uniqueword in vocab}\n",
    "for index,text in enumerate(training_set[\"Text\"]):\n",
    "    for word in text:\n",
    "        word_count[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studying</th>\n",
       "      <th>sign</th>\n",
       "      <th>09095350301</th>\n",
       "      <th>singapore</th>\n",
       "      <th>high</th>\n",
       "      <th>mas</th>\n",
       "      <th>if</th>\n",
       "      <th>tickets</th>\n",
       "      <th>18</th>\n",
       "      <th>skirt</th>\n",
       "      <th>...</th>\n",
       "      <th>la1</th>\n",
       "      <th>talks</th>\n",
       "      <th>raji</th>\n",
       "      <th>pa</th>\n",
       "      <th>smidgin</th>\n",
       "      <th>sheets</th>\n",
       "      <th>atural</th>\n",
       "      <th>responding</th>\n",
       "      <th>loneliness</th>\n",
       "      <th>missions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   studying  sign  09095350301  singapore  high  mas  if  tickets  18  skirt  \\\n",
       "0         0     0            0          0     0    0   1        0   0      0   \n",
       "1         0     0            0          0     0    0   0        0   0      0   \n",
       "2         0     0            0          0     0    0   0        0   0      0   \n",
       "3         0     0            0          0     0    0   1        0   0      0   \n",
       "4         0     0            0          0     0    0   0        0   0      0   \n",
       "\n",
       "   ...  la1  talks  raji  pa  smidgin  sheets  atural  responding  loneliness  \\\n",
       "0  ...    0      0     0   0        0       0       0           0           0   \n",
       "1  ...    0      0     0   0        0       0       0           0           0   \n",
       "2  ...    0      0     0   0        0       0       0           0           0   \n",
       "3  ...    0      0     0   0        0       0       0           0           0   \n",
       "4  ...    0      0     0   0        0       0       0           0           0   \n",
       "\n",
       "   missions  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 7798 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = pd.DataFrame(word_count)\n",
    "word_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>studying</th>\n",
       "      <th>sign</th>\n",
       "      <th>09095350301</th>\n",
       "      <th>singapore</th>\n",
       "      <th>high</th>\n",
       "      <th>mas</th>\n",
       "      <th>if</th>\n",
       "      <th>tickets</th>\n",
       "      <th>...</th>\n",
       "      <th>la1</th>\n",
       "      <th>talks</th>\n",
       "      <th>raji</th>\n",
       "      <th>pa</th>\n",
       "      <th>smidgin</th>\n",
       "      <th>sheets</th>\n",
       "      <th>atural</th>\n",
       "      <th>responding</th>\n",
       "      <th>loneliness</th>\n",
       "      <th>missions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[looks, like, u, wil, b, getting, a, headstart...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, noe, la, u, wana, pei, bf, oso, rite, k, l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>[2mro, i, am, not, coming, to, gym, machan, go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>spam</td>\n",
       "      <td>[todays, vodafone, numbers, ending, with, 4882...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[hi, hope, ur, day, good, back, from, walk, ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text  studying  sign  \\\n",
       "0   ham  [looks, like, u, wil, b, getting, a, headstart...         0     0   \n",
       "1   ham  [i, noe, la, u, wana, pei, bf, oso, rite, k, l...         0     0   \n",
       "2   ham  [2mro, i, am, not, coming, to, gym, machan, go...         0     0   \n",
       "3  spam  [todays, vodafone, numbers, ending, with, 4882...         0     0   \n",
       "4   ham  [hi, hope, ur, day, good, back, from, walk, ta...         0     0   \n",
       "\n",
       "   09095350301  singapore  high  mas  if  tickets  ...  la1  talks  raji  pa  \\\n",
       "0            0          0     0    0   1        0  ...    0      0     0   0   \n",
       "1            0          0     0    0   0        0  ...    0      0     0   0   \n",
       "2            0          0     0    0   0        0  ...    0      0     0   0   \n",
       "3            0          0     0    0   1        0  ...    0      0     0   0   \n",
       "4            0          0     0    0   0        0  ...    0      0     0   0   \n",
       "\n",
       "   smidgin  sheets  atural  responding  loneliness  missions  \n",
       "0        0       0       0           0           0         0  \n",
       "1        0       0       0           0           0         0  \n",
       "2        0       0       0           0           0         0  \n",
       "3        0       0       0           0           0         0  \n",
       "4        0       0       0           0           0         0  \n",
       "\n",
       "[5 rows x 7800 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating training_set with word_count\n",
    "final_training_set = pd.concat([training_set,word_count],axis=1)\n",
    "final_training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING SPAM FILTER\n",
    "\n",
    "When a new message comes in, the multinomial Naive Bayes algorithm will classify it based on the result of the two equations below\n",
    "\n",
    "1. $P(Spam|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })\\propto P(Spam) \\cdot\\prod _{ i=1 }^{ n }{ P({ w }_{ i }|Spam) } $\n",
    "\n",
    "2. $P(Ham|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })\\propto P(Ham) \\cdot\\prod _{ i=1 }^{ n }{ P({ w }_{ i }|Ham) } $\n",
    "\n",
    "If $P(Spam|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$ is greater than $P(Ham|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$, then the message is considered to be spam\n",
    "\n",
    "To calculate $P({ w }_{ i }|Spam)$ and $P({ w }_{ i }|Ham)$, the following two equations will be used\n",
    "\n",
    "3. $P({ w }_{ i }|Spam)=\\frac { { N }_{ { w }_{ i }|Spam }+\\alpha  }{ { N }_{ Spam }+\\alpha \\cdot { N }_{ Vocabulary } }$\n",
    "\n",
    "4. $P({ w }_{ i }|Ham)=\\frac { { N }_{ { w }_{ i }|Ham }+\\alpha  }{ { N }_{ Ham }+\\alpha \\cdot { N }_{ Vocabulary } }$\n",
    "\n",
    "where,\n",
    "\n",
    "$P({ w }_{ i }|Spam)$ = Number of times the word ${ w }_{ i }$ occurs in spam messages\n",
    "\n",
    "$P({ w }_{ i }|Ham)$ = Number of times the word ${ w }_{ i }$ occurs in Ham messages\n",
    "\n",
    "${ N }_{ Spam }$ = Total number of words in Spam messages\n",
    "\n",
    "${ N }_{ Ham }$ = Total number of words in Ham messages\n",
    "\n",
    "${ N }_{ Vocabulary }$ = Total number of words in vocabulary\n",
    "\n",
    "$\\alpha$ = Laplace smoothing. Set $\\alpha$ = 1\n",
    "\n",
    "\n",
    "Now I'll calculate the value of some terms(constant terms) that will be repeatedly used to avoid calculating it again and again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolating Spam and Ham messages\n",
    "\n",
    "spam = final_training_set[final_training_set[\"Label\"]==\"spam\"]\n",
    "ham = final_training_set[final_training_set[\"Label\"]==\"ham\"]\n",
    "\n",
    "#Calculating P(Spam) and P(Ham)\n",
    "\n",
    "p_spam = len(spam)/len(final_training_set)\n",
    "p_ham = len(ham)/len(final_training_set)\n",
    "\n",
    "#Calculating N_Spam and N_Ham\n",
    "\n",
    "words_per_spam_message = spam[\"Text\"].apply(len)\n",
    "n_spam = words_per_spam_message.sum()\n",
    "\n",
    "words_per_ham_message = ham[\"Text\"].apply(len)\n",
    "n_ham = words_per_ham_message.sum()\n",
    "\n",
    "#N_Vocabulary\n",
    "\n",
    "n_vocab = len(vocab)\n",
    "\n",
    "#Setting the value of Laplace Smoothing\n",
    "\n",
    "alpha = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be calculating the value of parameters $P({ w }_{ i }|Spam)$ and $P({ w }_{ i }|Ham)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_parameters = {uniqueword:0 for uniqueword in vocab}\n",
    "ham_parameters = {uniqueword:0 for uniqueword in vocab}\n",
    "\n",
    "for word in vocab:\n",
    "    n_word_given_spam = spam[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocab)\n",
    "    spam_parameters[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocab)\n",
    "    ham_parameters[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFYING A NEW MESSAGE\n",
    "\n",
    "Now that I have calculated all the parameters, I'll start building the spam filter.\n",
    "\n",
    "The spam filter is a function that:\n",
    "\n",
    "1. Takes in a message as an input\n",
    "2. Converts the line into words by removing punctuations and converting the words to lower case ${ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n }$\n",
    "3. Calculates $P(Spam|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$ and $P(Ham|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$\n",
    "3. Compares the value of $P(Spam|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$ and $P(Ham|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$ and:\n",
    "    1. If $P(Spam|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$ > $P(Ham|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$, the message will be classified as Spam\n",
    "    2. If $P(Spam|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$ < $P(Ham|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$, the message will be classified as Ham.\n",
    "    3. $P(Spam|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$ = $P(Ham|{ w }_{ 1 },{ w }_{ 2 },....,{ w }_{ n })$, the algorithm may need human help.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(text):\n",
    "    text = re.sub('\\W',' ',text)\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    p_spam_given_text = p_spam\n",
    "    p_ham_given_text = p_ham\n",
    "    \n",
    "    for word in text:\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_text *= spam_parameters[word]\n",
    "        if word in ham_parameters:\n",
    "            p_ham_given_text *= ham_parameters[word]\n",
    "    \n",
    "    print(\"P(Spam|message) = \",p_spam_given_text)\n",
    "    print(\"P(Ham|message) = \",p_ham_given_text)\n",
    "    \n",
    "    if p_spam_given_text > p_ham_given_text:\n",
    "        print(\"Spam\")\n",
    "    elif p_spam_given_text < p_ham_given_text:\n",
    "        print(\"Ham\")\n",
    "    else:\n",
    "        print(\"Equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message) =  8.490646913435681e-13\n",
      "P(Ham|message) =  1.1052417705809237e-15\n",
      "Spam\n"
     ]
    }
   ],
   "source": [
    "classification('CONGRATS!! WINNER!! Code to unlock : 12345')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message) =  1.0548661294420755e-16\n",
      "P(Ham|message) =  7.209864739040585e-12\n",
      "Ham\n"
     ]
    }
   ],
   "source": [
    "classification(\"I'll meet you there\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEASURING THE ACCURACY OF THE FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_test_set(text):\n",
    "    text = re.sub('\\W',' ',text)\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    p_spam_given_text = p_spam\n",
    "    p_ham_given_text = p_ham\n",
    "    \n",
    "    for word in text:\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_text *= spam_parameters[word]\n",
    "        if word in ham_parameters:\n",
    "            p_ham_given_text *= ham_parameters[word]\n",
    "    \n",
    "    if p_spam_given_text > p_ham_given_text:\n",
    "        return \"spam\"\n",
    "    elif p_spam_given_text < p_ham_given_text:\n",
    "        return \"ham\"\n",
    "    else:\n",
    "        return \"equal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Wherre's my boytoy ? :-(</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text Predicted\n",
       "0   ham                           Wherre's my boytoy ? :-(       ham\n",
       "1   ham          Later i guess. I needa do mcat study too.       ham\n",
       "2   ham             But i haf enuff space got like 4 mb...       ham\n",
       "3  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "4   ham  All sounds good. Fingers . Makes it difficult ...       ham"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new column in test set\n",
    "test_set[\"Predicted\"] = test_set[\"Text\"].apply(classification_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  1103\n",
      "Incorrect =  12\n",
      "Accuracy =  0.989237668161435\n"
     ]
    }
   ],
   "source": [
    "#Function to calculate the accuracy\n",
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row[\"Label\"] == row[\"Predicted\"]:\n",
    "        correct += 1\n",
    "print(\"Correct = \", correct)\n",
    "print(\"Incorrect = \", total-correct)\n",
    "print(\"Accuracy = \", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 98.9%, which indicates that the filter is really good. Out of the 1115 messages that the spam filter has not seen in training, it has classified 1103 messages correctly. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
